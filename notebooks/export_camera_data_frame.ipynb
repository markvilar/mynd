{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "733d0d25-2667-4e4e-a659-69482edd1054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-21 11:19:04.945\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m202\u001b[0m - \u001b[31m\u001b[1mbackend already has a loaded project\u001b[0m\n",
      "\u001b[32m2024-10-21 11:19:05.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_cameras_data_frame\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-21 11:19:05.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_cameras_data_frame\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mShape:   (2529, 22)\u001b[0m\n",
      "\u001b[32m2024-10-21 11:19:05.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_cameras_data_frame\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1mColumns: ['camera_key', 'camera_label', 'longitude', 'latitude', 'height', 'yaw', 'pitch', 'roll', 'altitude', 'backscatter', 'cdom', 'chlorophyll', 'conductivity', 'depth', 'exposure', 'exposure_logged', 'salinity', 'temperature', 'timestamp', 'trigger_time', 'negative_height', 'image_path']\u001b[0m\n",
      "\u001b[32m2024-10-21 11:19:05.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_cameras_data_frame\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-21 11:19:05.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_cameras_data_frame\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mWrote processed cameras: /data/kingston_snv_01/georef_semantics_test/r23m7ms0_20100606_001908_cameras_grayworld.csv\u001b[0m\n",
      "\u001b[32m2024-10-21 11:19:05.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_cameras_data_frame\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-21 11:19:05.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_cameras_data_frame\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mShape:   (2529, 22)\u001b[0m\n",
      "\u001b[32m2024-10-21 11:19:05.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_cameras_data_frame\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1mColumns: ['camera_key', 'camera_label', 'longitude', 'latitude', 'height', 'yaw', 'pitch', 'roll', 'altitude', 'backscatter', 'cdom', 'chlorophyll', 'conductivity', 'depth', 'exposure', 'exposure_logged', 'salinity', 'temperature', 'timestamp', 'trigger_time', 'negative_height', 'image_path']\u001b[0m\n",
      "\u001b[32m2024-10-21 11:19:05.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_cameras_data_frame\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-21 11:19:05.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_cameras_data_frame\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mWrote processed cameras: /data/kingston_snv_01/georef_semantics_test/r23m7ms0_20100606_001908_cameras_debayered.csv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from mynd.backend import metashape\n",
    "from mynd.camera import Camera\n",
    "from mynd.collections import CameraGroup\n",
    "from mynd.io import write_data_frame\n",
    "\n",
    "from mynd.utils.log import logger\n",
    "from mynd.utils.result import Ok, Err, Result\n",
    "\n",
    "\n",
    "CameraGroupID = CameraGroup.Identifier\n",
    "\n",
    "\n",
    "def tabulate_camera_identifiers(\n",
    "    identifiers: list[Camera.Identifier],\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"Converts a collection of camera identifiers to a data frame.\"\"\"\n",
    "    return pl.DataFrame(\n",
    "        [\n",
    "            {\"camera_key\": identifier.key, \"camera_label\": identifier.label}\n",
    "            for identifier in identifiers\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def tabulate_camera_references(\n",
    "    references: CameraGroup.References,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"Converts a collection of camera references to a data frame.\"\"\"\n",
    "    entries: list[dict] = list()\n",
    "    for index, identifier in enumerate(references.identifiers):\n",
    "\n",
    "        location: list | None = references.locations.get(identifier)\n",
    "        rotation: list | None = references.rotations.get(identifier)\n",
    "\n",
    "        entry: dict = {\n",
    "            \"camera_key\": identifier.key,\n",
    "            \"camera_label\": identifier.label,\n",
    "        }\n",
    "\n",
    "        if location:\n",
    "            entry.update(\n",
    "                {\n",
    "                    \"longitude\": location[0],\n",
    "                    \"latitude\": location[1],\n",
    "                    \"height\": location[2],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if rotation:\n",
    "            entry.update(\n",
    "                {\"yaw\": rotation[0], \"pitch\": rotation[1], \"roll\": rotation[2]}\n",
    "            )\n",
    "\n",
    "        entries.append(entry)\n",
    "\n",
    "    return pl.DataFrame(entries)\n",
    "\n",
    "\n",
    "def tabulate_camera_metadata(metadata: CameraGroup.Metadata) -> pl.DataFrame:\n",
    "    \"\"\"Converts a collection of camera metadata to a data frame.\"\"\"\n",
    "    entries: list[dict] = list()\n",
    "    for identifier, fields in metadata.fields.items():\n",
    "        entry: dict = {\n",
    "            \"camera_key\": identifier.key,\n",
    "            \"camera_label\": identifier.label,\n",
    "        }\n",
    "        entry.update(fields)\n",
    "        entries.append(entry)\n",
    "\n",
    "    return pl.DataFrame(entries)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "\n",
    "    target: str\n",
    "    destination: Path\n",
    "    extension: str\n",
    "\n",
    "\n",
    "def process_camera_data(cameras: CameraGroup, config: Config) -> pl.DataFrame:\n",
    "    \"\"\"Process camera data from various sources.\"\"\"\n",
    "\n",
    "    data_frames: dict[str, pl.DataFrame] = {\n",
    "        \"identifiers\": tabulate_camera_identifiers(\n",
    "            cameras.attributes.identifiers\n",
    "        ),\n",
    "        \"ref_estimates\": tabulate_camera_references(\n",
    "            cameras.reference_estimates\n",
    "        ),\n",
    "        \"ref_priors\": tabulate_camera_references(cameras.reference_priors),\n",
    "        \"metadata\": tabulate_camera_metadata(cameras.metadata),\n",
    "    }\n",
    "\n",
    "    # Join identifiers, reference estimates, and metadata\n",
    "    left: pl.DataFrame = data_frames.get(\"ref_estimates\")\n",
    "    for right in [data_frames.get(\"metadata\")]:\n",
    "        left: pl.DataFrame = left.join(\n",
    "            right, how=\"left\", on=[\"camera_key\", \"camera_label\"]\n",
    "        )\n",
    "\n",
    "    cameras: pl.DataFrame = left\n",
    "\n",
    "    # TODO: Add some fancy interpolation with reference priors\n",
    "    cameras: pl.DataFrame = cameras.sort(by=\"timestamp\")\n",
    "    cameras: pl.DataFrame = cameras.with_columns(\n",
    "        (-pl.col(\"height\")).alias(\"negative_height\")\n",
    "    )\n",
    "\n",
    "    # TODO: Filter out monochrome images\n",
    "    cameras: pl.DataFrame = cameras.filter(\n",
    "        pl.col(\"camera_label\").str.ends_with(\"LC16\")\n",
    "    )\n",
    "    cameras: pl.DataFrame = cameras.sort(by=\"camera_label\")\n",
    "\n",
    "    # Add file path\n",
    "    cameras: pl.DataFrame = cameras.with_columns(\n",
    "        pl.concat_str([pl.col(\"camera_label\"), pl.lit(config.extension)]).alias(\n",
    "            \"image_path\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return cameras\n",
    "\n",
    "\n",
    "def export_cameras_data_frame(config: Config) -> None:\n",
    "    \"\"\"Export cameras to a data frame.\"\"\"\n",
    "\n",
    "    target_group: CameraGroupID = retrieve_target_group(config.target)\n",
    "    camera_group: CameraGroup = metashape.camera_services.retrieve_camera_group(\n",
    "        target_group\n",
    "    ).unwrap()\n",
    "\n",
    "    # TODO: Add config to select base / sorting / interpolation\n",
    "\n",
    "    # TODO: Create data frame for camera - attributes - identifiers\n",
    "    processed_cameras: pl.DataFrame = process_camera_data(camera_group, config)\n",
    "\n",
    "    logger.info(\"\")\n",
    "    logger.info(f\"Shape:   {processed_cameras.shape}\")\n",
    "    logger.info(f\"Columns: {processed_cameras.columns}\")\n",
    "    logger.info(\"\")\n",
    "\n",
    "    write_result: Result = write_data_frame(\n",
    "        config.destination, processed_cameras\n",
    "    )\n",
    "    match write_result:\n",
    "        case Ok(path):\n",
    "            logger.info(f\"Wrote processed cameras: {path}\")\n",
    "        case Err(message):\n",
    "            logger.error(message)\n",
    "\n",
    "\n",
    "def retrieve_target_group(target: str) -> Optional[CameraGroupID]:\n",
    "    \"\"\"Retrieves the target group from the backend.\"\"\"\n",
    "    identifiers: list[CameraGroupID] = (\n",
    "        metashape.get_group_identifiers().unwrap()\n",
    "    )\n",
    "    mapping: dict[str, CameraGroupID] = {\n",
    "        identifier.label: identifier for identifier in identifiers\n",
    "    }\n",
    "    return mapping.get(target)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Main function.\"\"\"\n",
    "\n",
    "    # r23m7ms0_20100606_001908\n",
    "    # r23685bc_20100605_021022, r23685bc_20120530_233021, r23685bc_20140616_225022\n",
    "\n",
    "    GROUP_LABEL: str = \"r23m7ms0_20100606_001908\"\n",
    "    PROJECT: Path = Path(\n",
    "        \"/data/kingston_snv_01/acfr_metashape_projects_dev/r23m7ms0_lite_with_metadata.psz\"\n",
    "    )\n",
    "    OUTPUT_DIR: Path = Path(\"/data/kingston_snv_01/georef_semantics_test\")\n",
    "\n",
    "    configs: list[Config] = [\n",
    "        Config(\n",
    "            f\"{GROUP_LABEL}\",\n",
    "            Path(f\"{OUTPUT_DIR}/{GROUP_LABEL}_cameras_grayworld.csv\"),\n",
    "            extension=\".png\",\n",
    "        ),\n",
    "        Config(\n",
    "            f\"{GROUP_LABEL}\",\n",
    "            Path(f\"{OUTPUT_DIR}/{GROUP_LABEL}_cameras_debayered.csv\"),\n",
    "            extension=\".tiff\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    load_result: Result = metashape.load_project(PROJECT)\n",
    "    if load_result.is_err():\n",
    "        logger.error(load_result.err())\n",
    "\n",
    "    for config in configs:\n",
    "        export_cameras_data_frame(config)\n",
    "\n",
    "\n",
    "# Invoke main function\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
